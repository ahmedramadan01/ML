{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedramadan01/datascience/blob/main/ImageNet%20Challenge%20ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdHGB3sJLreE"
      },
      "source": [
        "# ImageNet challenge\n",
        "\n",
        "The goal is to implement a classifier that assigns the correct class to as many images as possible in a test data set\n",
        "\n",
        "Implementation:\n",
        "1. ResNet-50\n",
        "2. the implemented network can be trained and evaluated\n",
        "3. using the best weights to create the class mapping for the test data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei0RK3zwLreJ"
      },
      "source": [
        "<hr style=\"border-width: 5px\">\n",
        "\n",
        "### Vorbereitung\n",
        "The basic requirement, <font color=\"#aa0000\">install the</font> `tui-dl4cv` package und import afterward.\n",
        "\n",
        "for installation there are two ways.\n",
        "\n",
        "**(1) Install direct in this notebook:**\n",
        "execute the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stqavuy7LreJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "print(f\"Automatically install package for '{sys.executable}'\")\n",
        "!{sys.executable} -m pip install tui-dl4cv \\\n",
        "    --extra-index-url \"https://2022ws:xXCgQHZxxeNYchgryN7e@nikrgl.informatik.tu-ilmenau.de/api/v4/projects/1730/packages/pypi/simple\" \\\n",
        "    --no-cache --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5tgYDQnLreK"
      },
      "source": [
        "ODER\n",
        "\n",
        "**(2) Manuel Install in console:**\n",
        "Open (\"Anaconda Prompt\" unter Windows) and execute the following code:\n",
        "```text\n",
        "pip install tui-dl4cv --extra-index-url \"https://2022ws:xXCgQHZxxeNYchgryN7e@nikrgl.informatik.tu-ilmenau.de/api/v4/projects/1730/packages/pypi/simple\" --no-cache --upgrade\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpsDgkD6LreK"
      },
      "outputs": [],
      "source": [
        "# DL4CV Contest Dataset\n",
        "from tui_dl4cv.contest import DL4CVDataset\n",
        "\n",
        "# Function to visualize examples\n",
        "from tui_dl4cv.contest import plot_samples\n",
        "\n",
        "# Function to calculate all test results\n",
        "from tui_dl4cv.contest import compute_submission_results\n",
        "\n",
        "# Function to submit results\n",
        "from tui_dl4cv.contest import submit_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfUTJANQLreL"
      },
      "outputs": [],
      "source": [
        "# NumPy\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Torchvision\n",
        "import torchvision\n",
        "\n",
        "# PyTorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# Accuracy Metrics\n",
        "from torchmetrics import Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gzMPyXULreL"
      },
      "source": [
        "<hr style=\"border-width: 5px\">\n",
        "\n",
        "### DL4CV-Contest-Data set\n",
        "\n",
        "The DL4CV contest data set is based on the ImageNet data set and consists of images from 100 different classes, with each image being assigned exactly one class. All images are scaled so that the smaller side of the image is 100 pixels.\n",
        "\n",
        "The data set consists of 3 parts (engl. splits):\n",
        "- Training data (*train*): 50.000 images with associated class information\n",
        "- Validation data (*val*): 5.000 images with associated class information\n",
        "- Test data (*test*): 2.500 images withput classes informations (My Task)\n",
        "\n",
        "The code block below automatically downloads the data set and visualizes some random samples from the training data.\n",
        "\n",
        "<div style=\"background-color:#EAF2F8; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
        "&#9998; <b>Tips</b>\n",
        "<ul style=\"margin-bottom: 0px; margin-top: 0px\">\n",
        "    <li>This function can also be used to visualize results and specific problem cases.</li>\n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwScwAmJLreM"
      },
      "outputs": [],
      "source": [
        "# Data set creating\n",
        "train_dataset = DL4CVDataset(root='./', split='train')\n",
        "\n",
        "# 12 random Examples visualization\n",
        "plot_samples([train_dataset[i]\n",
        "              for i in np.random.permutation(len(train_dataset))[:12]],\n",
        "             class_names=train_dataset.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqNbzHe0LreN"
      },
      "source": [
        "<hr style=\"border-width: 5px\">\n",
        "\n",
        "### 2 Training des Netzwerks\n",
        "\n",
        "Implementation PyTorch-Lightning-Class (`pl.LightningModule`) for Training, Validierung und Test.\n",
        "---\n",
        "#### PyTorch-Lightning-Klasse definieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt7jvkDYLreN"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import Accuracy\n",
        "\n",
        "imageNetMean = [0.485, 0.456, 0.406]\n",
        "imageNetStd = [0.229, 0.224, 0.225]\n",
        "\n",
        "class MyNetworkLightningModule(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Load ResNet50 as the base model\n",
        "        self.network = torchvision.models.resnet50(pretrained=True)\n",
        "        \n",
        "        # Freeze all layers of the base model\n",
        "        for param in self.network.parameters():\n",
        "            param.requiresGrad = False\n",
        "\n",
        "        # Add a custom classifier on top of the base model\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = torch.nn.Linear(num_ftrs, 100)\n",
        "\n",
        "        # Metrics for validation\n",
        "        self.accuracy_top1 = Accuracy(task='multiclass',\n",
        "                                      num_classes=100,\n",
        "                                      top_k=1)\n",
        "        self.accuracy_top5 = Accuracy(task='multiclass',\n",
        "                                      num_classes=100,\n",
        "                                      top_k=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "\n",
        "        # Forward Propagation\n",
        "        y = self.network(x)\n",
        "\n",
        "        # Determine loss\n",
        "        loss = F.cross_entropy(y, t)\n",
        "\n",
        "        # Log the loss\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "\n",
        "        # Forward Propagation\n",
        "        y = self.network(x)\n",
        "        loss = F.cross_entropy(y, t)\n",
        "        \n",
        "        # Log the loss and metrics\n",
        "        self.log('val_loss', loss,\n",
        "                 on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_acc_top1', self.accuracy_top1(y, t),\n",
        "                 on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_acc_top5', self.accuracy_top5(y, t),\n",
        "                 on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss \n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.network.fc.parameters(),\n",
        "                               lr=0.01,\n",
        "                               momentum=0.9)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"Dataloader for training\"\"\"\n",
        "        # Preprocessing and data augmentation\n",
        "        transforms = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize(224),\n",
        "            torchvision.transforms.RandomCrop(224),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize(mean = imageNetMean,\n",
        "                                             std = imageNetStd)\n",
        "        ])\n",
        "\n",
        "        # Load the dataset\n",
        "        dataset = DL4CVDataset(root='./', split='train', transform=transforms)\n",
        "\n",
        "        # Create the dataloader and return it\n",
        "        return torch.utils.data.DataLoader(dataset,\n",
        "                                           batch_size=100,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=1)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"Dataloader for Validation\"\"\"\n",
        "        # Preprocessing\n",
        "        transforms = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize(256),\n",
        "            torchvision.transforms.CenterCrop(224),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize(mean = imageNetMean,\n",
        "                                             std = imageNetStd)\n",
        "        ])\n",
        "\n",
        "        # load data set\n",
        "        dataset = DL4CVDataset(root='./', split='val', transform=transforms)\n",
        "\n",
        "        # Build and return dataloader\n",
        "        \n",
        "        return torch.utils.data.DataLoader(dataset,\n",
        "                                           batch_size=100,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=1)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        \"\"\"Dataloader for Test data\"\"\"\n",
        "        # Preprocessing\n",
        "        transforms = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize(224),\n",
        "            torchvision.transforms.CenterCrop(224),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize(mean = imageNetMean,\n",
        "                                             std = imageNetStd)\n",
        "        ])\n",
        "\n",
        "        # load data set\n",
        "        dataset = DL4CVDataset(root='./', split='test', transform=transforms)\n",
        "\n",
        "        # Create and return dataloader\n",
        "        return torch.utils.data.DataLoader(dataset,\n",
        "                                           batch_size=100,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": false,
        "id": "Hl_PY0z3LreN"
      },
      "outputs": [],
      "source": [
        "# Create network object\n",
        "network = MyNetworkLightningModule()\n",
        "\n",
        "# Create a callback to save the best weights\n",
        "checkpoint_cb = pl.callbacks.ModelCheckpoint(\n",
        "    save_top_k=1,\n",
        "    verbose=False,\n",
        "    monitor='val_acc_top1',\n",
        "    mode='max',\n",
        ")\n",
        "\n",
        "# Create trainer object\n",
        "trainer = pl.Trainer(default_root_dir='./results',\n",
        "                     accelerator='gpu',    \n",
        "                     devices=1,\n",
        "                     #  overfit_batches=0.1,\n",
        "                     max_epochs=10,\n",
        "                     callbacks=checkpoint_cb)\n",
        "\n",
        "# training networks\n",
        "trainer.fit(network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbJJTIQRLreO"
      },
      "source": [
        "---\n",
        "#### Lernprozess visualisieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwXKtipRLreO"
      },
      "outputs": [],
      "source": [
        "# for Jupyter Notebook and Colab\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./results/lightning_logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFlI76wDLreO"
      },
      "source": [
        "<hr style=\"border-width: 5px\">\n",
        "\n",
        "### 3 Implementation on unknown Test data\n",
        "After successful training, the network with the best weights can be used to predict the class assignment on the unknown test data.\n",
        "\n",
        "#### Apply Network and specify results on Test data \n",
        "\n",
        "It is good practice to visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_PEnanRLreO"
      },
      "outputs": [],
      "source": [
        "# load best weights\n",
        "print(f\"Lade Checkpoint: {checkpoint_cb.best_model_path}\")\n",
        "best_network = MyNetworkLightningModule.load_from_checkpoint(checkpoint_cb.best_model_path)\n",
        "\n",
        "# Put the network in evaluation mode\n",
        "best_network.eval()\n",
        "\n",
        "# Visualize first twelve samples of first batch of test data\n",
        "for filenames, (x, _) in network.test_dataloader():\n",
        "    # Forward Propagation\n",
        "    logits = best_network(x.to(best_network.device))\n",
        "\n",
        "    # Designate the class with the highest affiliation as a class    \n",
        "    y = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "    # Prepare images (move channel axis backwards)    \n",
        "    imgs = x.permute(0, 2, 3, 1).cpu().numpy()\n",
        "\n",
        "    # Reverse preprocessing if necessary\n",
        "\n",
        "    plot_samples([(filenames[i], (imgs[i], y[i])) for i in range(12)],\n",
        "                 class_names=network.test_dataloader().dataset.classes)\n",
        "\n",
        "    # cancel after first Batch \n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAYoYieHLreO"
      },
      "source": [
        "#### Abschließend können die Ergebnisse eingereicht werden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "26LZJK2KLreO"
      },
      "outputs": [],
      "source": [
        "# load best weights\n",
        "print(f\"Lade Checkpoint: {checkpoint_cb.best_model_path}\")\n",
        "#best_network = MyNetworkLightningModule.load_from_checkpoint(checkpoint_cb.best_model_path)\n",
        "\n",
        "# Ergebnisse für die Submission bestimmen\n",
        "#submission_results = compute_submission_results(best_network)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a36bc1df758689cab85bd3cddbf19760f70742c7b9e9867a3c5834cb2b9245b9"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}